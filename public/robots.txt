# Robots.txt for Exploraria - AI Travel Guide

# Allow all search engines to crawl everything
User-agent: *
Allow: /

# Specific permissions for major search engines
User-agent: Googlebot
Allow: /

User-agent: Bingbot
Allow: /

User-agent: Twitterbot
Allow: /

User-agent: facebookexternalhit
Allow: /

# Block access to internal admin pages
User-agent: *
Disallow: /cms

# Allow crawling of all content pages
Allow: /blog
Allow: /explore
Allow: /destinations

# Sitemap location
Sitemap: https://lovable.exploraria.ai/sitemap.xml

# Crawl delay (optional - be respectful to server resources)
Crawl-delay: 1
